<TeXmacs|1.0.7.21>

<style|article>

<\body>
  \;

  \;

  <doc-data|<doc-title|Topics in Algebraic Computation>>

  <\table-of-contents|toc>
    <vspace*|1fn><with|font-series|bold|math-font-series|bold|1<space|2spc>Introduction>
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-1><vspace|0.5fn>

    <with|par-left|1tab|1.1<space|2spc>Overview
    \ <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-2>>

    <with|par-left|1tab|1.2<space|2spc>References
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-3>>

    <with|par-left|1tab|1.3<space|2spc>Evaluation
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-4>>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|2<space|2spc>Hermite
    Canonical Form> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-5><vspace|0.5fn>

    <with|par-left|1tab|2.1<space|2spc>Sweep-out Method
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-6>>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|3<space|2spc>LUP
    decomposition of Matrix and Applications>
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-7><vspace|0.5fn>

    <with|par-left|2tab|3.0.1<space|2spc>Efficient Methods for Multiplying
    Matrices and Polynomials <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-8>>

    <with|par-left|2tab|3.0.2<space|2spc>Matrix Multiplication
    <with|mode|math|\<Leftrightarrow\>> Matrix Inversion
    \ <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-9>>

    <with|par-left|2tab|3.0.3<space|2spc>Computing matrix determinant.
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-10>>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|4<space|2spc>Upper
    Hessenberg Form> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-11><vspace|0.5fn>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|5<space|2spc>Smith
    Canonical Form> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-12><vspace|0.5fn>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|6<space|2spc>Fast
    Fourier Transform> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-13><vspace|0.5fn>

    <with|par-left|1tab|6.1<space|2spc>Bit-Complexity of Fast Fourier
    Transform <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-14>>

    <with|par-left|1tab|6.2<space|2spc>Schonhage-Strassen algorithm
    \ <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-15>>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|7<space|2spc>Computational
    complexity of Fundamental Integer operations.>
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-16><vspace|0.5fn>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|8<space|2spc>Greatest
    Common Divisor> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-17><vspace|0.5fn>

    <with|par-left|1tab|8.1<space|2spc>Euclidean GCD Algorithm
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-18>>

    <with|par-left|1tab|8.2<space|2spc>Half-GCD Algorithm
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-19>>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|9<space|2spc>Polynomial
    Factoring> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-20><vspace|0.5fn>

    <with|par-left|1tab|9.1<space|2spc>Berlekamp's Method
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-21>>

    <with|par-left|1tab|9.2<space|2spc>Cantor-Zassenhaus randomized algorithm
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-22>>

    <with|par-left|1tab|9.3<space|2spc>Factorization over
    <with|mode|math|\<bbb-Z\><around*|[|x|]>>
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-23>>

    <with|par-left|2tab|9.3.1<space|2spc>Hensel Lifting
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-24>>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|10<space|2spc>Ideals
    and Varieties> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-25><vspace|0.5fn>

    <with|par-left|1tab|10.1<space|2spc>Multivariate Polynomials
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-26>>

    <with|par-left|1tab|10.2<space|2spc>Division algorithm in
    <with|mode|math|\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-27>>
  </table-of-contents>

  <new-page>

  <section|Introduction>

  <subsection|Overview >

  Course primarily concentrates on algorithmic approach to compute algebraic
  objects. Focus of the course will be on Algebraic objects that are built
  using Integers, Polynomials and Matrices. Algorithms for computing \ the
  following will be discussed as part of the course:

  <\enumerate-roman>
    <item>Addition, Multiplication, Inversion, GCD for Integers.\ 

    <item>Strassen's algorithm for Matrix Multiplication.

    <item>Solving systems of Linear Equations.

    <item>Computing Characteristic polynomial, Minimal Polynomail, Inverse
    Polynomial.

    <item>Conversion of Matrices into standard canonical forms like Hermite
    Canonical Form (HCF).

    <item>Berlekamp's Algorithm for Polynomial factorization\ 
  </enumerate-roman>

  Asymptotic computational complexity analysis and correctness proofs for
  these algorithms will also be covered. Beyond this, some more advanced
  topics will be discussed :

  <\enumerate-roman>
    <item>Lower bounds on complexity of Algebraic operations.

    <item>Grobner Basis algorithm.

    <item>Lattice reduction algorithm via <math|L<rsup|3>>.

    <item>Function Field Sieve, Number Field Sieve algorithm for factoring
    integers and finding discrete log.
  </enumerate-roman>

  <subsection|References>

  Except for few topics course most content of the course is taken from
  Research publications. For standard topics, following text books are
  suggested:

  <\enumerate-roman>
    <item>Aho, Hopcroft, Ullman : Design and Analysis of Algorithms.

    <item>Grobner Basis from Ideals, Varieties and Algorithms by Cox, Little,
    O'shea

    <item>Lattice Reduction from Algorithmic aspects of Algebraic Number
    Theory by Cohen.

    <item>Computational Algebra. by Abijit Das
  </enumerate-roman>

  <subsection|Evaluation>

  Course has 3 evaluation components. Components and their weightage in the
  evaluation are as follows:

  <\enumerate-roman>
    <item>Mid Semester Examination - 30%

    <item>Termpaper Assignment - 20%

    <item>End Semester Examination - 50%
  </enumerate-roman>

  <hrule><page-break>

  <section|Hermite Canonical Form>

  We shall consider matrices with elements from a Field. Today's discussion
  will focus on key results and algorithms for conversion of matrices in to
  Hermite Normal Form (HNF), computing inverse of a square matrix, testing
  the consistency of linear equations and LUB decomposition of matrices.
  These forms of matrix help in computing matrix parameters like rank, basis
  of row and column, basis of null space. \ 

  We shall state the following result without proof. Subsequently we progress
  towards the construction.

  <\theorem>
    <dueto|Rank Factorization Theorem>If <math|A> is an <math|m\<times\>n>
    matrix with rank <math|r>. Then there exist two full-rank matrices
    <math|B> and <math|C> with orders <math|m\<times\>r> and
    <math|r\<times\>n> such that <math|A=B\<times\>C>.\ 
  </theorem>

  <\notation>
    Linear space spanned by columns of a matrix <math|X> is denoted by
    <math|Col.Sp<around*|(|X|)>> and Linear space spanned by rows of a matrix
    <math|X> is denoted by <math|Row.Sp<around*|(|X|)>>.
  </notation>

  <\notation>
    <dueto|Augumented Matrix>If <math|A,B> are two matrices of orders
    <math|m\<times\>k> and <math|n\<times\>k>, then the matrix
    <math|<around*|[|A:B|]> > of order <math|<around*|(|m+n|)>\<times\>k>
    obtained by extending rows of <math|A> with corresponding rows of <math|
    B>.
  </notation>

  <\note>
    System of linear equations : <math|A x=b> is consistent if
    <math|b\<in\>Col.Sp<around*|(|A|)>>. Putting this in another way
    <math|Rank<around*|(|A|)>=<around*|(|Rank<around*|(|<around*|[|A:b|]>|)>|)>>.
  </note>

  <\definition>
    <dueto|Null Space>If <math|A> is an <math|n\<times\>n> matrix in
    <math|\<bbb-F\>> then space of vectors <math|v\<in\>\<bbb-F\><rsup|n>>
    such that <math|A v =0> is called Null Space.
  </definition>

  <\note>
    For a given matrix <math|A>, <math|A x =0> has a unique solution
    <math|\<Leftrightarrow\>> <math|A> has a full rank. More generally
    <math|A<rsub|m\<times\>n> x =b> has a unique solution
    <math|\<Leftrightarrow\> m=n> and <math|A> has a full rank. \ Otherwise
    there are more than one solutions.
  </note>

  <\definition>
    <dueto|Generalized Inverse>Let <math|A> be an <math|m\<times\>n> matrix.
    A matrix <math|G> is called generalized inverse of <math|A> if <math|G
    b=b<rprime|'>> is a solution of <math|A x=b>, whenever <math|A x=b> has a
    solution.
  </definition>

  <\note>
    If <math|A> is an invertible square matrix, then Generalized Inverse of
    <math|A> is <math|A<rsup|-1>>.
  </note>

  <subsection|Sweep-out Method>

  Following operations on any <math|m\<times\>n> matrix are called elementary
  row operations:

  <\enumerate-roman>
    <item>Interchange two rows. This corresponds to pre-multiplying the
    matrix by a Permutation Matrix.

    <item>Multiply a rwo by a non-zero constant. This corresponds to
    pre-multiplying the matrix with matrix of the form
    <math|<matrix|<tformat|<table|<row|<cell|1>|<cell|0>|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|0>>|<row|<cell|0>|<cell|1>|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|0>>|<row|<cell|0>|<cell|0>|<cell|1>|<cell|0>|<cell|\<ldots\>>|<cell|\<vdots\>>>|<row|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|\<alpha\>>|<cell|\<ldots\>>|<cell|\<vdots\>>>|<row|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|\<ldots\>>|<cell|\<ddots\>>|<cell|.>>>>>>
    which is a diagonal matrix and only of the diagonal elements different
    from 1.

    <item>Addition of two rows. This corresponds to pre-multiplying the
    matrix with matrix of the form <math|I<rsub|n\<times\>n>+A<rsub|i j>>
    where \ <math|A<rsub|x y>=<around*|(|a<rsub|i j>|)><rsub|n\<times\>n>>
    and <math|a<rsub|i j>=1> if <math|i=x,j=y> and <math|0> otherwise.
  </enumerate-roman>

  <\note>
    It is easy to observe that each of the operation above is invertible. It
    is easy to construct the corresponding inverse matrix for each of the
    operations. However, these operations dont commute in general.
  </note>

  <\lemma>
    If a matrix <math|A> in a field <math|\<bbb-F\>> can be reduced to a
    matrix <math|A<rprime|'>> by series of elementary row operations with
    corresponding pre-multiplication matrices as
    <math|P<rsub|1>,P<rsub|2>,\<ldots\>,P<rsub|t>> then
    <math|A<rprime|'>=<around*|(|<big|prod><rsub|i=1><rsup|t>P<rsub|i>|)>A>.
  </lemma>

  <\note>
    In all complexity calculations we consider addition and multiplication on
    the underlying field are <math|O<around*|(|1|)>> operations.
  </note>

  While matrix computation in general takes <math|O<around*|(|n<rsup|3>|)>>
  steps, given the special nature of matrices corresponding to elementary row
  operations, multiplication by these matrices can be realized much more
  effeciently.\ 

  <\lemma>
    Given an <math|n\<times\>n> matrix <math|M> in a field <math|\<bbb-F\>>.
    There exists an <math|O<around*|(|n|)>> algorithm to compute the
    resulting matrix obtained by multiplying a matrix correponding to
    elementary row operations.\ 
  </lemma>

  <hrule>

  <\definition>
    <dueto|Hermite Canonical Form>A Square matrix M is said to be HCF if:

    <\enumerate-roman>
      <item><math|M> is upper triangular.

      <item>Diagonal elements of <math|M> are either <math|0> or <math|1>.

      <item>If diagonal element is <math|1> then all other entries in that
      column are <math|0>.

      <item>If diagonal element is 0, then all other entries in that row are
      <math|0>.
    </enumerate-roman>
  </definition>

  <hrule>

  <\theorem>
    <dueto|Hermite Canonical Form>Any Square matrix whose elements are from a
    field, can be converted to <with|font-series|bold|Hermite Canonical Form>
    using elementary row operations in <math|O<around*|(|n<rsup|3>|)>> time.
  </theorem>

  <\proof>
    We shall specify the steps to construct the required canonical form with
    inductive justification:

    Let <math|A=<around*|(|a<rsub|i j>|)><rsub|n\<times\>n>> be the given
    matrix with elements from a Field.

    If <math|a<rsub|1 1>\<neq\>0>, then sweep out the first column using
    <math|a<rsub|1 1>> as pivot.

    If <math|a<rsub|1 1>=0>, then if <math|\<exists\>i\<gtr\>1> such that
    <math|a<rsub|i 1>\<neq\>0>, then interchange rows <math|i,1> and sweep
    out the first column using the new <math|a<rsub| 1 1>> as the pivot.
    Otherwise, whole of first column is zero.

    Suppose, that after <math|k-1> steps, the
    <math|<around*|(|k-1|)>\<times\><around*|(|k-1|)>> principal sub-matrix
    is in <math|HCF>.\ 

    If <math|a<rsub|k k>\<neq\>0> sweep out the <math|k<rsup|th>> column
    using <math|a<rsub|k k>>.

    If <math|a<rsub|k k>=0>, and if <math|\<exists\>l\<gtr\>k> such that
    <math|a<rsub|k l>\<gtr\>0>, If <math|\<exists\>i\<less\>k>, such that
    <math|a<rsub|i k>\<neq\>0>, but <math|a<rsub|i i>=0>, then interchange
    <math|i,j> rows and sweep out the <math|k<rsup|th>> column using the new
    <math|a<rsub|p k>> as the pivot.

    After these operations the principle submatrix of the resulting matrix of
    order <math|k> is in <math|H C F>.

    These operations suggest the algorithm and use at most
    <math|O<around*|(|n<rsup|3>|)>> field operations.
  </proof>

  <hrule>

  <\note>
    Above method clearly works for non square matrices as well.
  </note>

  <\theorem>
    Consider a system of equations <math|A x=b>, where <math|A> is an
    <math|n\<times\>n> matrix in a field <math|\<bbb-F\>>. If an augmented
    matrix formed as <math|<around*|[|A:I<rsub|n\<times\>n>:b|]>> can be
    redued to its Hermite Canonical Form as
    <math|<around*|[|H<rsub|n\<times\>n>:G<rsub|n\<times\>n>:d|]>>. Then
    following statements hold:

    <\enumerate-roman>
      <item>The <math|#1s> on the diagonal of <math|H> is rank of <math|A>.

      <item><math|G> is a generalized inverse of <math|A>.

      <item>System of equations <math|A x=b> is consistent
      <math|\<Leftrightarrow\>> <math|d<rsub|i>=0> whenever <math|h<rsub|i
      i>=0>.

      <item>Any solution of the system of equations <math|A x=b> is of the
      form: <math|d+<around*|(|1-H|)>z,z\<in\>\<bbb-F\><rsup|n>>.

      <item>The columns of <math|H> form a basis for Null Space of <math|A>.

      <item>Let <math|1\<leqslant\>i<rsub|1>\<leqslant\>i<rsub|2> \<ldots\>
      \<leqslant\>n> be such that <math|h<rsub|i<rsub|j>,i<rsub|j>>=1> and
      all <math|h<rsub|i i>=0> and <math|B=<around*|[|A<rsub|\<ast\>
      i<rsub|1>>:A<rsub|*\<ast\> i<rsub|2>>:\<ldots\>:A<rsub|\<ast\>
      i<rsub|r>>|]>> and <math|C=<matrix|<tformat|<table|<row|<cell|H<rsub|i<rsub|1>
      \<ast\>>>>|<row|<cell|H<rsub|i<rsub|2>
      \<ast\>>>>|<row|<cell|\<vdots\>>>|<row|<cell|H<rsub|i<rsub|r>
      \<ast\>>>>>>>> then <math|A=B \<times\>C>.
    </enumerate-roman>
  </theorem>

  <\proof>
    -: FILL THE DETAILS :-

    \;
  </proof>

  <hrule>

  <\theorem>
    Let <math|A> be an <math|n\<times\>n> non singular matrix. Then there is
    a permutation matrix <math|P>, s.t. all principal sub-matrices of <math|P
    A> are non-singular.
  </theorem>

  <\proof>
    Steps are similar to Theorem:14. In each step collect all the
    permutations required in order. Then <math|P> is the product of all those
    permutation matrices taken in order.
  </proof>

  <hrule>

  <\theorem>
    <dueto|LU Decomposition>Let <math|A> be an <math|n\<times\>n> non
    singular matrix, such that all the principal sub matrices of <math|A> are
    non-singular, then we can write <math|A= L U>, where\ 

    <\eqnarray*>
      <tformat|<table|<row|<cell|L=<matrix|<tformat|<table|<row|<cell|1>|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|0>>|<row|<cell|l<rsub|2
      1>>|<cell|1>|<cell|0>|<cell|\<ldots\>>|<cell|0>>|<row|<cell|l<rsub|3
      1>>|<cell|l<rsub|3 2>>|<cell|1>|<cell|\<ldots\>>|<cell|0>>|<row|<cell|\<vdots\>>|<cell|\<vdots\>>|<cell|\<vdots\>>|<cell|>|<cell|\<vdots\>>>|<row|<cell|l<rsub|n
      1>>|<cell|l<rsub|n 2>>|<cell|l<rsub|n
      3>>|<cell|\<ldots\>>|<cell|1>>>>><rsub|n*\<times\>n>>|<cell|>|<cell|>>>>
    </eqnarray*>

    <\eqnarray*>
      <tformat|<table|<row|<cell|U=<matrix|<tformat|<table|<row|<cell|u<rsub|1
      1>>|<cell|u<rsub|1 2>>|<cell|\<ldots\>>|<cell|u<rsub|1
      n>>>|<row|<cell|0>|<cell|u<rsub|2 2>>|<cell|\<ldots\>>|<cell|u<rsub|2
      n>>>|<row|<cell|0>|<cell|0>|<cell|>|<cell|\<vdots\>>>|<row|<cell|\<vdots\>>|<cell|\<vdots\>>|<cell|>|<cell|>>|<row|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|u<rsub|n
      n>>>>>><rsub|n\<times\>n>>|<cell|>|<cell|>>>>
    </eqnarray*>

    and both <math|L,U> can be computed in <math|O<around*|(|n<rsup|3>|)>>
    time.
  </theorem>

  <\proof>
    Since <math|A> is a such that all its principal sub matrices are
    non-singular we can solve for each of <math|l<rsub|i j>> and
    <math|u<rsub|i j>> by multiplying <math|L> and <math|U> and then
    comparing the result with <math|A>.
  </proof>

  <hrule><page-break>

  <section|LUP decomposition of Matrix and Applications>

  <subsubsection|Efficient Methods for Multiplying Matrices and Polynomials>

  While general <math|n\<times\>n> matrix and <math|n<rsup|th>> order
  Polynomial multiplication takes <math|O<around*|(|n<rsup|3>|)>> time.
  Efficient methods for multiplication exist. Earliest successful attempt can
  be traced back to Karatsuba's algorithm for matrix multiplication published
  around 1950. This method is believed to be motivation for research towards
  more efficient matrix multiplication as well and first successful efficient
  algorithm for matrix multiplication has been published by Strassen in 1967.\ 

  Karatsuba's Algorithm for Multiplication of two polynomials. Let
  <math|P<around*|(|x|)>,Q<around*|(|x|)>> be two degree-<math|2
  n,n\<in\>\<bbb-N\>>, polynomials expressed as:
  <math|P<around*|(|x|)>=x<rsup|n>P<rsub|1><around*|(|x|)>+P<rsub|0><around*|(|x|)>,Q<around*|(|x|)>=x<rsup|n>Q<rsub|1><around*|(|x|)>+Q<rsub|0><around*|(|x|)>>.
  The product of both the polynomials can be computed if we have
  <math|P<rsub|0>Q<rsub|0>,P<rsub|1>Q<rsub|0>+P<rsub|0>Q<rsub|1>,P<rsub|1>Q<rsub|1>>
  computed, which normally requires computing four multiplications. However
  by using extra addition which is cost effective than multiplication we can
  reduce the number of required multiplications to three, as follows: We can
  compute <math|P<rsub|0>Q<rsub|0>,P<rsub|1>Q<rsub|1>,<around*|(|P<rsub|1>+P<rsub|0>|)><around*|(|Q<rsub|1>+Q<rsub|0>|)>-P<rsub|0>Q<rsub|0>-P<rsub|1>Q<rsub|1>>
  which precisely give the 3 expressions required for computing product with
  only 3 multiplications. This suggests a recursive divide and conquor
  algorithm of order complexity: <math|O<around*|(|n<rsup|log<rsup|3><rsub|2>>|)>>
  as opposed to the normal method which require
  <math|O<around*|(|n<rsup|2>|)>> time.

  Strassen's algorithm for computing the product of a matrices is similar,
  however require computing more non-trivial expressions. To compute product
  of two matrices of order <math|2n\<times\>2n>, if we visualize the matrices
  as follows:

  <\eqnarray*>
    <tformat|<table|<row|<cell|C<rsub|2n\<times\>2n>=A<rsub|2n
    \<times\>2n>B<rsub|2n\<times\>2n>>|<cell|>|<cell|>>>>
  </eqnarray*>

  <\eqnarray*>
    <tformat|<table|<row|<cell|<matrix|<tformat|<table|<row|<cell|C<rsup|0><rsub|n*\<times\>n>>|<cell|C<rsup|1><rsub|n\<times\>n>>>|<row|<cell|C<rsup|2><rsub|n\<times\>n>>|<cell|C<rsup|3><rsub|n\<times\>n>>>>>><rsub|2*n\<times\>2n>=<matrix|<tformat|<table|<row|<cell|A<rsup|0><rsub|n\<times\>n>>|<cell|A<rsup|1><rsub|n\<times\>n>>>|<row|<cell|A<rsup|2><rsub|n\<times\>n>>|<cell|A<rsup|3><rsub|n\<times\>n>>>>>><rsub|2n\<times\>2n><matrix|<tformat|<table|<row|<cell|B<rsub|n\<times\>n><rsup|0>>|<cell|B<rsup|1><rsub|n\<times\>n>>>|<row|<cell|B<rsup|2><rsub|n\<times\>n>>|<cell|B<rsup|3><rsub|n\<times\>n>>>>>><rsub|2n\<times\>2n>>|<cell|>|<cell|>>>>
  </eqnarray*>

  In the above scheme, computing matrix <math|C> requires computing
  <math|C<rsup|i><rsub|n\<times\>n>> and it requires computing products of 8
  sub-matrices: <math|A<rsup|0>B<rsup|0>,A<rsup|1>B<rsup|2>,A<rsup|0>B<rsup|1>,A<rsup|1>B<rsup|3>,A<rsup|2>B<rsup|0>,A<rsup|3>B<rsup|2>,A<rsup|2>B<rsup|1>,A<rsup|3>B<rsup|3>>.
  However, we can reduce this to compting <math|7> products, by introducing
  extra additions which are cheaper than computing products, as follows -
  compute the following 7 expressions:

  <\eqnarray*>
    <tformat|<table|<row|<cell|m<rsub|1>=<around*|(|A<rsub|n\<times\>n><rsup|1>-A<rsub|n\<times\>n><rsup|3>|)><around*|(|B<rsub|n\<times\>n><rsup|0>+B<rsub|n\<times\>n><rsup|3>|)>>|<cell|>|<cell|>>>>
  </eqnarray*>

  <\eqnarray*>
    <tformat|<table|<row|<cell|m<rsub|2>=<around*|(|A<rsub|n\<times\>n><rsup|0>+A<rsub|n\<times\>n><rsup|3>|)><around*|(|B<rsub|n\<times\>n><rsup|0>+B<rsub|n\<times\>n><rsup|3>|)>>|<cell|>|<cell|>>>>
  </eqnarray*>

  <\eqnarray*>
    <tformat|<table|<row|<cell|m<rsub|3>=<around*|(|A<rsub|n\<times\>n><rsup|0>-A<rsub|n\<times\>n><rsup|2>|)><around*|(|B<rsub|n\<times\>n><rsup|0>+B<rsub|n*\<times\>n><rsup|1>|)>>|<cell|>|<cell|>>>>
  </eqnarray*>

  <\eqnarray*>
    <tformat|<table|<row|<cell|m<rsub|4>=<around*|(|A<rsub|n\<times\>n><rsup|0>+A<rsub|n\<times\>n><rsup|1>|)><around*|(|B<rsub|n\<times\>n><rsup|3>|)>>|<cell|>|<cell|>>>>
  </eqnarray*>

  <\eqnarray*>
    <tformat|<table|<row|<cell|m<rsub|5>=<around*|(|A<rsub|n\<times\>n><rsup|0>|)><around*|(|B<rsub|n*\<times\>n><rsup|1>-B<rsub|n\<times\>n><rsup|3>|)>>|<cell|>|<cell|>>>>
  </eqnarray*>

  <\eqnarray*>
    <tformat|<table|<row|<cell|m<rsub|6>=<around*|(|A<rsub|n\<times\>n><rsup|3>|)><around*|(|B<rsub|n\<times\>n><rsup|2>-B<rsub|n\<times\>n><rsup|0>|)>>|<cell|>|<cell|>>>>
  </eqnarray*>

  <\eqnarray*>
    <tformat|<table|<row|<cell|m<rsub|7>=<around*|(|A<rsub|n\<times\>n><rsup|2>+A<rsub|n\<times\>n><rsup|1>|)><around*|(|B<rsub|n\<times\>n><rsup|0>|)>>|<cell|>|<cell|>>>>
  </eqnarray*>

  which in total require computing <math|7> products of order
  <math|n\<times\>n>. Then matrix <math|C> can be computed as\ 

  <\eqnarray*>
    <tformat|<table|<row|<cell|C=<matrix|<tformat|<table|<row|<cell|m<rsub|1>+m<rsub|2>-m<rsub|4>+m<rsub|6>>|<cell|m<rsub|4>+m<rsub|5>>>|<row|<cell|m<rsub|6>+m<rsub|7>>|<cell|m<rsub|2>-m<rsub|3>+m<rsub|5>-m<rsub|7>>>>>><rsub|2n\<times\>2n>>|<cell|>|<cell|>>>>
  </eqnarray*>

  This procedure, clearly suggests a divide and conquer algorithm. If
  <math|T<around*|(|n|)>> denotes the time required for computing a matrix of
  order <math|n\<times\>n> then <math|T<around*|(|n|)>=7
  T<around*|(|<frac|n|2>|)>+18<around*|(|<frac|n<rsup|2>|4>|)>>. Since the
  above procedure requires computing <math|7> products and 18 sums of order
  <math|<frac|n|2>\<times\><frac|n|2>>. Then
  <math|T<around*|(|n|)>=O<around*|(|n<rsup|log<rsub|2><rsup|7>>|)>=O<around*|(|n<rsup|\<sim\>2.81>|)>.>

  <\note>
    In the above method clearly works only when the order of matrix is a
    power of 2. Given a matrix of arbitrary order, we embed the it in a
    larger square matrix whose order is a power of 2 to use the above method.
  </note>

  <\note>
    Strassen's Algorithm being the first efficient method for multiplication
    of matrices, has created the interest in the question if multiplication
    can be performed better.\ 
  </note>

  <\notation>
    Time complexity for matrix multiplication of <math|n\<times\>n> matrices
    is denoted as <math|M<around*|(|n|)>=O<around*|(|n<rsup|\<omega\>>|)>>.
    If <math|\<omega\>=2+\<varepsilon\>>, <math|\<varepsilon\>> is called the
    exponent of linear algebra.\ 
  </notation>

  <hrule>

  <subsubsection|Matrix Multiplication <math|\<Leftrightarrow\>> Matrix
  Inversion >

  <\theorem>
    Matrix multiplication is no harder than Matrix Inversion.
  </theorem>

  <\proof>
    Suppose there exists and algorithm <math|\<cal-A\>> to invert a Matrix.
    Then one can construct an algorithm <math|\<cal-B\>> for multiplication
    as follows:\ 

    Let <math|X,Y> be two <math|n\<times\>n> matrices to be multiplied,\ 

    construct <math|D=<matrix|<tformat|<table|<row|<cell|I<rsub|n\<times\>n>>|<cell|X>|<cell|Y>>|<row|<cell|O<rsub|n\<times\>n>>|<cell|I<rsub|n\<times\>n>>|<cell|Y>>|<row|<cell|O<rsub|n*\<times\>n>>|<cell|O<rsub|n\<times\>n>>|<cell|I<rsub|n*\<times\>n>>>>>><rsub|3n\<times\>3n>>.
    \ Then the matrix <math|D> is invertible and inverse given as
    <math|D<rsup|-1>=<matrix|<tformat|<table|<row|<cell|I<rsub|n\<times\>n>>|<cell|-X>|<cell|X
    Y>>|<row|<cell|O<rsub|n\<times\>n>>|<cell|I<rsub|n\<times\>n>>|<cell|-Y>>|<row|<cell|O<rsub|n\<times\>n>>|<cell|O<rsub|n\<times\>n>>|<cell|I<rsub|n\<times\>n>>>>>><rsub|3n\<times\>3n>>.
    This can be verified by explicit computation.

    \;

    So, we shall construct algorithm <math|\<cal-B\>> as follows:

    1. Accept two matrices <math|X<rsub|n\<times\>n>,Y<rsub|n\<times\>n>>.

    2. Construct the matrix <math|D> as illustrated above.

    3. Call Algorithm <math|\<cal-A\>> with input as <math|D> to get
    <math|D<rsup|-1>>.

    4. Product of <math|X,Y> is the right principal submatrix of
    <math|D<rsup|-1>> of order <math|n\<times\>n>.
  </proof>

  <hrule>

  <\lemma>
    If <math|A> is an <math|2n\<times\>2n> matrix. written as
    <math|A=<matrix|<tformat|<table|<row|<cell|A<rsub|11>>|<cell|A<rsub|12>>>|<row|<cell|A<rsub|21>>|<cell|A<rsub|22>>>>>><rsub|2n\<times\>2n>>
    each <math|A<rsub|i j>> an <math|n\<times\>n> sub-matrix. If <math|A> is
    non-singular then <math|A<rsub|11>> is non singular and the inverse of
    <math|A> is given as:

    <\eqnarray*>
      <tformat|<table|<row|<cell|A<rsup|-1>=<matrix|<tformat|<table|<row|<cell|A<rsub|11><rsup|-1>+A<rsup|-1><rsub|11>A<rsub|12>S<rsup|-1>A<rsub|21>A<rsub|11><rsup|-1>>|<cell|-A<rsub|11><rsup|-1>A<rsub|12>S<rsup|-1>>>|<row|<cell|-S<rsup|-1>A<rsub|21>A<rsub|11><rsup|-1>>|<cell|S<rsup|-1>>>>>>>|<cell|>|<cell|>>>>
    </eqnarray*>

    where <math|S=A<rsub|22>-A<rsub|21\<space\>>A<rsub|11><rsup|-1>A<rsub|12>>.
  </lemma>

  <\theorem>
    Matrix Inversion is no harder than Matrix multiplication.
  </theorem>

  <hrule>

  <\theorem>
    If A is a matrix that is invertible, then <math|A> can be written as
    <math|A=L U P> where <math|P> is a product of permutation matrices.
  </theorem>

  <\proof>
    From Theorem 17. If <math|A> is invertible then there exist permutation
    matrices <math|Q<rsub|1>,Q<rsub|2>,\<ldots\>,Q<rsub|t>> such that <math|A
    <around*|(|<big|prod><rsub|i=1><rsup|t>Q<rsub|i>|)>=B> is such that all
    principal sub-matrices of <math|B> are invertible.

    Let <math|Q=<big|prod><rsub|i=1><rsup|t>Q<rsub|i>>. Clearly <math|Q> is
    invertible, since each of <math|Q<rsub|i>> is invertible. By Theorem 18.
    <math|B=A Q> can be decomposed as <math|L U>. So, <math|A Q=L U>. So,
    choose <math|P=Q<rsup|-1>>.
  </proof>

  We state the following theorem without proof.

  <hrule>

  <\theorem>
    <math|L U P> decomposition of matrix <math|A> can be computed in
    <math|O<around*|(|M<around*|(|n|)>|)>> time.
  </theorem>

  <math|L U P> decomposition of matrix can be used to compute determinant of
  the matrix efficiently.

  <hrule>

  <subsubsection|Computing matrix determinant.>

  <\lemma>
    If we can decompose a matrix <math|A= L U P\<nocomma\>,>then
    <math|det<around*|(|A|)>=<around*|(|-1|)><rsup|Sgn<around*|(|P|)>>det<around*|(|U|)>>.
  </lemma>

  <\proof>
    If <math|A= L U P> then we have <math|det<around*|(|A|)>=det<around*|(|L|)>det<around*|(|U|)>det<around*|(|P|)>>.

    Since <math|P> is a product of permuation matrices,
    <math|det<around*|(|P|)>=<around*|(|-1|)><rsup|Sgn<around*|(|P|)>>>,
    which can be computed in <math|O<around*|(|n|)>> time. Since <math|L> is
    a lower triangular matrices with all its diagonal elements <math|1>, we
    have <math|det<around*|(|L|)>=1>. Hence,
    <math|det<around*|(|A|)>=<around*|(|-1|)><rsup|Sgn<around*|(|P|)>>det<around*|(|U|)>>.
  </proof>

  This suggests an algorithm to compute the determinant in
  <math|O<around*|(|M<around*|(|n|)>|)>> steps.

  <hrule>

  <\theorem>
    Determinant of an <math|n\<times\>n> matrix can be computed in
    <math|O<around*|(|M<around*|(|n|)>|)>> steps.
  </theorem>

  <\proof>
    Compute the determinant if matrix <math|A<rsub|n\<times\>n>> as follows:

    <\enumerate-numeric>
      <item>Compute LUP decomposition of matrix <math|A = L U P>

      <item>Compute <math|det<around*|(|P|)>=<around*|(|-1|)><rsup|Sgn<around*|(|P|)>>>.

      <item>Compute <math|det<around*|(|U|)>=<big|prod><rsub|i=1><rsup|n>u<rsub|i
      i>>.

      <item><math|det<around*|(|A|)>=<around*|(|-1|)><rsup|Sgn<around*|(|P|)>><big|prod><rsub|i=1><rsup|n>u<rsub|i
      i>.>
    </enumerate-numeric>

    Since, <math|L U P> decomposition requries
    <math|O<around*|(|M<around*|(|n|)>|)>> steps and all other steps require
    <math|O<around*|(|n|)>> steps, determinant can be computed in
    <math|O<around*|(|M<around*|(|n|)>|)>> steps.
  </proof>

  <hrule>

  Lemma 23. Suggests a very efficient method for computing inverse of a non
  singular matrix. If <math|A=<matrix|<tformat|<table|<row|<cell|A<rsub|11>>|<cell|A<rsub|12>>>|<row|<cell|A<rsub|21>>|<cell|A<rsub|22>>>>>><rsub|2n\<times\>2n>>
  is a non singular matrix, and is upper triangular then
  <math|A<rsub|21>=0<rsub|n\<times\>n>>. <math|A<rsub|11>,A<rsub|22>> are
  upper triangular and so is <math|A<rsup|-1>=<matrix|<tformat|<table|<row|<cell|A<rsub|11><rsup|-1>>|<cell|-A<rsub|11><rsup|-1>A<rsub|12>A<rsub|22><rsup|-1>>>|<row|<cell|0<rsub|n\<times\>n>>|<cell|A<rsub|22><rsup|-1>>>>>><rsub|2n\<times\>2n>>.
  This suggests a very simple divide and conquer algorithm for computing
  inverse of an upper triangular matrix:

  \;

  InvertUTMatrix(<math|A>):

  <\enumerate-numeric>
    <item><math|A<rsub|11><rsup|-1>> <math|\<leftarrow\>>
    InvertUTMatrix<math|<around*|(|A<rsub|11>|)>>.

    <item><math|A<rsub|22><rsup|-1> \<leftarrow\>>
    InvertUTMatrix(<math|A<rsub|22>>).

    <item><math|A<rsup|-1>=<matrix|<tformat|<table|<row|<cell|A<rsub|11><rsup|-1>>|<cell|-A<rsub|11><rsup|-1>A<rsub|12>A<rsub|22><rsup|-1>>>|<row|<cell|0>|<cell|A<rsub|22><rsup|-1>>>>>>>.
  </enumerate-numeric>

  If <math|T<around*|(|n|)>> is the number of steps required to compute the
  inverse of <math|n\<times\>n> upper triangular matrix. Then
  <math|T<around*|(|n|)>=2 T<around*|(|<frac|n|2>|)>+2<around*|(|<frac|n|2>|)><rsup|3>+<around*|(|<frac|n|2>|)><rsup|2>>.\ 

  \;

  <with|font-series|bold|A MATRIX MULTIPLICATION INEQUALITY IS ASSUMED HERE!>
  FILL THE DETAILS.

  \;

  For a general matrix, we can use <math|L U P> decomposition and use the
  above method to invert the matrices <math|U,L>. <math|P> being a
  permutation matrix is invertible in <math|O<around*|(|n|)>> steps for an
  <math|n\<times\>n> matrix. So, Inversion of matrix can be done in
  <math|O<around*|(|M<around*|(|n|)>|)>> time.

  <\theorem>
    Given a non singular matrix <math|A>. Inverse of <math|A >can be computed
    in <math|O<around*|(|M<around*|(|n|)>|)>> steps.
  </theorem>

  So the methods above describe computing determinant and inverse of a
  matrix. Determinant of the matrix can be defined over a Ring but all the
  above operations assume a field. This restriction can be overcome in case
  of Integral Domains by embedding the elements of given matrix into the
  field of fractions. But the issue is growth of intermediate fractions, so
  even though total number of operations wont change, each operation may
  become very costly. So an alternative for integer matrices is to compute
  determinants in prime fields and then combine the results.

  Given a matrix <math|M> whose entries are integers, suppose there is an
  apriori known bound on <math|det<around*|(|M|)>\<less\>\<b-Delta\>>. Let
  <math|p<rsub|1>,p<rsub|2>,\<ldots\>,p<rsub|r>> be distinct primes such that
  <math|\<b-Delta\>\<less\>p<rsub|1>p<rsub|2>\<ldots\>p<rsub|r>>. Then
  compute <math|\<b-Delta\><rsub|i>=det<around*|(|M|)><around*|(|mod
  p<rsub|i>|)>> and combine the results by using Chinese Reminder Theorem to
  obtain <math|det<around*|(|M|)><around*|(|mod
  p<rsub|1>p<rsub|2>\<ldots\>p<rsub|r>|)>=d>. But since
  <math|\<b-Delta\>\<less\>p<rsub|1>\<ldots\>p<rsub|r>> we have
  <math|d=det<around*|(|M|)>>. Such a bound on determinant can be obtained
  using hardamard bound on determinant given as
  <math|\<b-Delta\>\<leqslant\><big|prod><rsub|1\<leqslant\>i\<leqslant\>n><around*|(|<big|sum><rsub|1\<leqslant\>j\<leqslant\>n><around*|\||m<rsub|i
  j>|\|><rsup|2>|)><rsup|<frac|1|2>>>.

  \ <hrule><new-page>

  <section|Upper Hessenberg Form>

  <\definition>
    <dueto|Characteristic Polynomial>Characteristic Polynomial of a matrix
    <math|A> denoted as <math|C h<rsub|A><around*|(|x|)>\<assign\>det<around*|(|x
    I-A|)>>.
  </definition>

  <\lemma>
    If <math|A> is an <math|n\<times\>n> matrix then <math|deg<around*|(|C
    h<rsub|A><around*|(|x|)>|)>=n>.
  </lemma>

  <\theorem>
    <dueto|Caley Hamilton>Every square matrix satistifies its Characteristic
    polynomial.
  </theorem>

  <\definition>
    <dueto|Minimal Polynomial>A Minimal polynomial of matrix <math|A> is
    least degree monic polynomial <math|m<rsub|A><around*|(|x|)>> such that
    <math|m<rsub|A><around*|(|A|)>=O<rsub|n\<times\>n>>.
  </definition>

  <hrule>

  <\lemma>
    If <math|A<rsub|n\<times\>n>> is a matrix then
    <math|m<rsub|A><around*|(|x|)><around*|\||C
    h<rsub|A><around*|(|x|)>|\<nobracket\>>>.
  </lemma>

  <\proof>
    Suppose <math|m<rsub|A><around*|(|x|)>\<nmid\>C h<rsub|A><around*|(|x|)>>
    then by remainder theorem, we have <math|C
    h<rsub|A><around*|(|x|)>=m<rsub|A><around*|(|x|)>q<around*|(|x|)>+r<around*|(|x|)>>

    where \ <math|deg<around*|(|r|)>\<less\>deg<around*|(|m|)>>.

    But, by definition we have <math|m<rsub|A><around*|(|A|)>=0<rsub|n*\<times\>n>>.
    and Caley-Hamilton theorem <math|C h<rsub|A><around*|(|A|)>=0>.

    So, <math|C h<rsub|A><around*|(|A|)>=0=m<rsub|A><around*|(|A|)>q<around*|(|A|)>+r<around*|(|A|)>=0+r<around*|(|A|)>>

    <math|\<Rightarrow\>r<around*|(|A|)>=0>. Contradicting the minimality of
    <math|m<rsub|A><around*|(|x|)>>.
  </proof>

  <hrule>

  <\proposition>
    If <math|A> is a matrix and <math|\<rho\><around*|(|x|)>> is an
    irreducible polynomial which divides <math|C h<rsub|A><around*|(|x|)>>
    then <math|\<rho\><around*|(|x|)><around*|\||m<rsub|A><around*|(|x|)>|\<nobracket\>>>.
  </proposition>

  <\proof>
    Since <math|m<rsub|A><around*|(|x|)>> is a polynomial we have
    <math|<around*|(|x-y|)><around*|\||m<rsub|A><around*|(|x|)>-m<rsub|A><around*|(|y|)>|\<nobracket\>>>.\ 

    So we can write <math|m<rsub|A><around*|(|x|)>-m<rsub|A><around*|(|y|)>=<around*|(|x-y|)>k<around*|(|x,y|)>>.

    Substituting <math|x=\<lambda\>I> and <math|y=A>, we have
    <math|m<rsub|A><around*|(|\<lambda\>I|)>-m<rsub|A><around*|(|A|)>=m<rsub|A><around*|(|\<lambda\>I|)>>
    (by definition. of <math|m<rsub|A>>)

    <math|\<Rightarrow\>m<rsub|A><around*|(|\<lambda\>I|)>=<around*|(|\<lambda\>I-A|)>k<around*|(|\<lambda\>I,A|)>>

    <math|\<Rightarrow\>m<rsub|A><around*|(|\<lambda\>|)>I=<around*|(|\<lambda\>I-A|)>k<around*|(|\<lambda\>I,A|)>>

    <math|\<Rightarrow\>det<around*|(|m<rsub|A><around*|(|\<lambda\>|)>I|)>=det<around*|(|\<lambda\>I-A|)>det<around*|(|k<around*|(|\<lambda\>I,A|)>|)>>

    <math|\<Rightarrow\><around*|(|m<rsub|A><around*|(|\<lambda\>|)>|)><rsup|n>=C
    h<rsub|A><around*|(|\<lambda\>|)>det<around*|(|k<around*|(|\<lambda\>I,A|)>|)>>

    So, if <math|\<rho\><around*|(|\<lambda\>|)><around*|\||C
    h<rsub|A><around*|(|\<lambda\>|)>|\<nobracket\>>> then
    <math|\<rho\><around*|(|\<lambda\>|)><around*|\||<around*|(|m<rsub|A><around*|(|\<lambda\>|)>|)><rsup|n>|\<nobracket\>>>.
    But since <math|\<rho\><around*|(|x|)>> is irreducible
    <math|\<rho\><around*|(|x|)><around*|\||m<rsub|A><around*|(|x|)>|\<nobracket\>>>.
  </proof>

  <hrule>

  <\corollary>
    The distinct roots of characteristic polynomial and minimal polynomials
    of a matrix are the same they differ only in multiplicities.
  </corollary>

  How to compute the minimal polynomial for a given matrix? It is clear to
  see that <math|I,A,\<ldots\>,A<rsup|n>> are linearly dependent, since
  characteristic polynomial is of degree <math|n>. So find smallest <math|r>
  such that <math|I,A,\<ldots\>,A<rsup|r>> are linearly dependent, <math|r>
  will be the deg of the minimal polynomial of <math|A> and coefficients of
  minimal polynomial can be obtained as coefficients of linear dependence.
  This can be done using Guassian Elimination which takes
  <math|O<around*|(|n<rsup|4>|)>> time. This however is not the best, there
  exist algorithms to compute minimal polynomial in
  <math|O<around*|(|n<rsup|3>|)>> time.

  How to compute the characteristic polynomial? Let
  <math|F<rsub|n><around*|[|x|]>> be the vector space of all polynomial over
  <math|F> whose degree is atmost <math|n>. Then
  <math|F<rsub|n><around*|[|x|]>> has a dimension of <math|n+1> over <math|F>
  with a basis <math|<around*|{|1,x,x<rsup|2>,\<ldots\>,x<rsup|n>|}>>. We
  shall give a more non trivial basis for <math|F<rsub|n><around*|[|x|]>>.\ 

  Let <math|c<rsub|i>,1\<leqslant\>i\<leqslant\>n> be <math|n> distinct
  elements of <math|F>. We shall define polynomials,
  <math|p<rsub|i><around*|(|x|)>=<frac|<around*|(|x-c<rsub|1>|)><around*|(|x-c<rsub|2>|)>\<ldots\><around*|(|x-c<rsub|i-1>|)>\<ldots\><around*|(|x-c<rsub|i+1>|)>\<ldots\><around*|(|x-c<rsub|n>|)>|<around*|(|c<rsub|i>-c<rsub|1>|)><around*|(|c<rsub|i>-c<rsub|2>|)>\<ldots\><around*|(|c<rsub|i>-c<rsub|n>|)>>>
  for <math|1\<leqslant\>i\<leqslant\>n>. Then we can observe that
  <math|p<rsub|i><around*|(|c<rsub|j>|)>=1\<Leftrightarrow\>i=j> and <math|0>
  otherwise.\ 

  <\lemma>
    <math|<around*|{|p<rsub|1><around*|(|x|)>,\<ldots\>p<rsub|n><around*|(|x|)>|}>>
    forms a basis for <math|F<rsub|n><around*|[|x|]>> over <math|F>.
  </lemma>

  Any <math|f<around*|(|x|)>\<in\>F<rsub|n><around*|[|x|]>> can be written as
  <math|f<around*|(|x|)>=<big|sum><rsub|1\<leqslant\>i\<leqslant\>n>f<around*|(|c<rsub|i>|)>p<rsub|i><around*|(|x|)>>.
  This observation can be used to compute the characteristic polynomial of
  matrix <math|M>. We compute <math|C h<rsub|A><around*|(|c<rsub|i>|)>=det<around*|(|c<rsub|i
  >I-A|)>> for all <math|i>. Then write <math|C
  h<rsub|A><around*|(|x|)>=<big|sum><rsub|1\<leqslant\>i\<leqslant\>n>C
  h<rsub|A><around*|(|c<rsub|i>|)>p<rsub|i><around*|(|x|)>>. Since computing
  <math|n\<times\>n> determinant in <math|F> takes
  <math|O<around*|(|M<around*|(|n|)>|)>> time computing characteristic
  polynomial takes <math|O<around*|(|n M<around*|(|n|)>|)>> time.

  \;

  <\definition>
    Let <math|A,B> be two <math|n\<times\>n> matrices. They are said to be
    similar if there exists an invertible matrix <math|C> such that <math|A=C
    B C<rsup|-1>>.
  </definition>

  <\note>
    Similarity is an equivalence relation.
  </note>

  <\lemma>
    If <math|A,B> are similar then they have same characteristic polynomial.
  </lemma>

  <\exercise>
    Find two non-similar matrices which have same characteristic polynomial.
  </exercise>

  \;

  <\definition>
    <dueto|Upper Hessenberg Form>A matrix of the following form is said to be
    in upper hessenberg form.

    <\equation*>
      <matrix|<tformat|<table|<row|<cell|h<rsub|11>>|<cell|h<rsub|12>>|<cell|h<rsub|13>>|<cell|\<ldots\>>|<cell|h<rsub|1
      n-1>>|<cell|h<rsub|1n>>>|<row|<cell|k<rsub|2>>|<cell|h<rsub|22>>|<cell|h<rsub|23>>|<cell|\<ldots\>>|<cell|h<rsub|2
      n-1>>|<cell|h<rsub|2n>>>|<row|<cell|0>|<cell|k<rsub|3>>|<cell|h<rsub|33>>|<cell|\<ldots\>>|<cell|h<rsub|3
      n-1>>|<cell|h<rsub|3n>>>|<row|<cell|0>|<cell|0>|<cell|k<rsub|4>>|<cell|\<ldots\>>|<cell|h<rsub|4
      n-1>>|<cell|h<rsub|4n>>>|<row|<cell|\<vdots\>>|<cell|>|<cell|>|<cell|>|<cell|>|<cell|\<vdots\>>>|<row|<cell|0>|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|k<rsub|n>>|<cell|h<rsub|n
      n>>>>>><rsub|n\<times\>n>
    </equation*>
  </definition>

  <\theorem>
    Given a matrix <math|A> we can apply a series of similarity transforms on
    it to get it into Upper Hessenberg Form.
  </theorem>

  <section|Smith Canonical Form>

  <\definition>
    <dueto|Non-derogatory Matrix>A matrix <math|M> is said to be
    non-derogatory if minimal polynomial of matrix
    <math|P<rsub|M><around*|(|x|)>> is same as characterisic polynomial of
    <math|M>.
  </definition>

  <\definition>
    <dueto|Elementary Jordan Matrix>A matrix of the following form is called
    Elementary Jordan Matrix.

    <\equation*>
      J<rsub|n><around*|(|c|)>=<matrix|<tformat|<table|<row|<cell|c>|<cell|0>|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|0>>|<row|<cell|1>|<cell|c>|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|0>>|<row|<cell|0>|<cell|1>|<cell|c>|<cell|0>|<cell|\<ldots\>>|<cell|0>>|<row|<cell|>|<cell|>|<cell|>|<cell|>|<cell|\<vdots\>>|<cell|>>|<row|<cell|0>|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|1>|<cell|c>>>>><rsub|n\<times\>n>
    </equation*>
  </definition>

  <\note>
    Elementary Jordan Matrix is Non-derogatory matrix and that can be
    observed by computing the successive powers of the matrix that minimal
    polynomial cannot have degree less than <math|n>.
  </note>

  <\definition>
    <dueto|Companion matrix of Polynomial>Companion matrix of the polynomial
    <math|p<around*|(|x|)>=x<rsup|n>+a<rsub|n-1>x<rsup|n-1>+\<ldots\>+a<rsub|1>x+a<rsub|0>>
    denoted by <math|C<around*|(|p|)>> is the matrix of the following form:

    <\equation*>
      <matrix|<tformat|<table|<row|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|0>|<cell|-a<rsub|0>>>|<row|<cell|1>|<cell|0>|<cell|\<ldots\>>|<cell|0>|<cell|-a<rsub|1>>>|<row|<cell|\<vdots\>>|<cell|>|<cell|>|<cell|>|<cell|>>|<row|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|1>|<cell|-a<rsub|n-1>>>>>><rsub|n\<times\>n>
    </equation*>
  </definition>

  \;

  <\note>
    It is easy to observe that characteristic polynomial of
    <math|C<around*|(|p|)>> is <math|p<around*|(|x|)>>.
  </note>

  <\notation>
    Henceforth we shall denote characteristic polynomial of a matrix M as
    <math|C h<rsub|M><around*|(|x|)>>.
  </notation>

  <\definition>
    <dueto|Direct Sum>The direct sum of two matrices square matrices
    <math|A<rsub|n\<times\>n>,B<rsub|m\<times\>m>> is the matrix
    <math|<matrix|<tformat|<table|<row|<cell|A>|<cell|0>>|<row|<cell|0>|<cell|B>>>>><rsub|<around*|(|m+n|)>\<times\><around*|(|m+n|)>>>
    and is denoted as <math|A\<oplus\>B>.
  </definition>

  <\lemma>
    <math|det<around*|(|A\<oplus\>B|)>=det<around*|(|A|)>det<around*|(|B|)>>
  </lemma>

  We shall state the following result without proof.

  <\theorem>
    <dueto|Jordan Canonical Form>Every matrix is similar to a direct sum of
    elementary jordan matrices, which is unique upto a permutation of
    elementary jordan blocks.
  </theorem>

  <\notation>
    We shall denote <math|F> for a field and <math|F<around*|[|x|]>> for ring
    of polynomials over field <math|F>. We shall denote the set of
    <math|n\<times\>n> matrices in ring <math|R> as
    <math|M<rsub|n\<times\>n><around*|(|R|)>>.
  </notation>

  <\definition>
    <dueto|Rational Canonical Form>Let <math|M=
    \<oplus\><rsub|k=1><rsup|s>C<around*|(|d<rsub|k>|)>>, where
    <math|d<rsub|1>,d<rsub|2>,\<ldots\>,d<rsub|s>> are non-constant monic
    polynomials in <math|F<around*|[|x|]>> such that
    <math|d<rsub|i><around*|\||d<rsub|i+1>|\<nobracket\>>>. Then <math|M> is
    said to be in Rational Canonical Form.
  </definition>

  <\definition>
    <dueto|Invariant Factors>If a matrix <math|A> is <math|\<sim\>> to
    <math|M= \<oplus\><rsub|k=1><rsup|s>C<around*|(|d<rsub|k>|)>> then the
    polynomials <math|d<rsub|i>> are called invariant factors of <math|A>.
  </definition>

  Following results show why Rational Canonical Form is useful in
  computational prespective.

  <\lemma>
    Minimal polynomaial of a matrix <math|M=
    \<oplus\><rsub|j=1><rsup|s>C<around*|(|d<rsub|j>|)>> is
    <math|LCM<around*|(|d<rsub|1>,\<ldots\>d<rsub|s>|)>>.
  </lemma>

  <hrule>

  <\theorem>
    If <math|d<rsub|1>,d<rsub|2>,\<ldots\>d<rsub|s>> are invariant factors of
    <math|A>, then

    <\enumerate-roman>
      <item><math|m<rsub|A><around*|(|x|)>=d<rsub|s><around*|(|x|)>>

      <item><math|C h<rsub|A><around*|(|x|)>=d<rsub|1>d<rsub|2>\<ldots\>d<rsub|s>>
    </enumerate-roman>
  </theorem>

  <\proof>
    \;
  </proof>

  <hrule>

  <\definition>
    A matrix <math|P> in <math|M<rsub|n\<times\>n><around*|(|F<around*|[|x|]>|)>>
    is said to be unit if there exist a matrix
    <math|Q\<in\>M<rsub|n\<times\>n><around*|(|F<around*|[|x|]>|)>> such that
    <math|P Q=I>.
  </definition>

  <\lemma>
    If matrices <math|P,Q> are units then so is <math|P Q>.
  </lemma>

  <\lemma>
    If matrix <math|P\<in\>M<rsub|n\<times\>n><around*|(|F<around*|[|x|]>|)>>
    is unit then <math|det<around*|(|P|)>\<in\>F>.
  </lemma>

  In the following discussion, following operations on matrices are treated
  as elementary row operations:

  <\enumerate-roman>
    <item>interchange two rows.

    <item>multiply a row by an element of <math|F<around*|[|x|]>> and add it
    to another row.
  </enumerate-roman>

  Both the above operations correspond to multiplication of original matrix
  by another matrix in <math|M<rsub|n\<times\>n><around*|(|F<around*|[|x|]>|)>>.

  <\lemma>
    Matrices corresponding to elementary row operations are units.
  </lemma>

  <\definition>
    <dueto|Unimodular Matrix>Products of elementary row matrices and
    elementary column matrices are called <with|font-series|bold|Unimodular>.
  </definition>

  We shall state the following theorem without proof.

  <\theorem>
    A matrix is a unit iff it is unimodular.
  </theorem>

  <\definition>
    Let <math|A,B\<in\>M<rsub|n\<times\>n><around*|(|F<around*|[|x|]>|)>>.
    Then <math|A> is said to be equivalent to <math|B>, if there are units
    <math|P,Q> such that <math|P A Q=B>.
  </definition>

  <\definition>
    Let <math|A\<in\>M<rsub|n\<times\>n><around*|(|F<around*|[|x|]>|)>> then
    for <math|1\<leqslant\>k\<leqslant\>n> let <math|d<rsub|k><around*|(|A|)>
    >denote the gcd of all <math|k\<times\>k> minors of <math|A>. Then
    <math|d<rsub|k><around*|(|A|)>> is called the <math|k<rsup|th>>
    determinant divisor of <math|A>.
  </definition>

  <\lemma>
    If two matrices in <math|M<rsub|n*\<times\>n><around*|(|F<around*|[|x|]>|)>>
    are similar then they have the same determinantal divisors.
  </lemma>

  <\note>
    The above notion can also be exnted to rectangular matrices.
  </note>

  <\note>
    <math|gcd<around*|(|f<rsub|1>,\<ldots\>f<rsub|n>|)>\<neq\>0\<Leftrightarrow\>>atleast
    one of <math|f<rsub|i>> is non-zero.
  </note>

  <\definition>
    <dueto|Determinant Rank>Determinant rank of a matrix <math|A> denoted by
    <math|\<rho\><around*|(|A|)>> is the largest integer <math|r> for which
    <math|d<rsub|r><around*|(|A|)>\<neq\>0>.
  </definition>

  <hrule>

  <\theorem>
    If <math|A> is a matrix in <math|M<rsub|n\<times\>n><around*|(|F<around*|[|x|]>|)>>
    then for <math|1\<leqslant\>k\<leqslant\>\<rho\><around*|(|A|)>>
    <math|d<rsub|k><around*|(|A|)><around*|\||d<rsub|k+1><around*|(|A|)>|\<nobracket\>>>.
  </theorem>

  <\proof>
    \;
  </proof>

  <hrule>

  <\theorem>
    <dueto|Smith Canonical Form>Every non-zero matrix
    <math|A\<in\>M<rsub|n\<times\>n><around*|(|F<around*|[|x|]>|)>> with
    <math|r=\<rho\><around*|(|A|)>> is equivalent to matrix of the following
    form

    <\equation*>
      <matrix|<tformat|<table|<row|<cell|f<rsub|1>>|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|0>|<cell|0>>|<row|<cell|0>|<cell|f<rsub|2>>|<cell|0>|<cell|\<ldots\>>|<cell|0>|<cell|0>>|<row|<cell|0>|<cell|0>|<cell|f<rsub|3>>|<cell|\<ldots\>>|<cell|0>|<cell|0>>|<row|<cell|\<vdots\>>|<cell|\<vdots\>>|<cell|\<vdots\>>|<cell|>|<cell|\<vdots\>>|<cell|\<vdots\>>>|<row|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|f<rsub|r>>|<cell|\<ldots\>>|<cell|0>>|<row|<cell|0>|<cell|0>|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|0>>|<row|<cell|\<vdots\>>|<cell|>|<cell|>|<cell|>|<cell|>|<cell|\<vdots\>>>|<row|<cell|0>|<cell|0>|<cell|0>|<cell|0>|<cell|\<ldots\>>|<cell|0>>>>><rsub|n*\<times\>n>
    </equation*>

    where <math|f<rsub|i>\<in\>F<around*|[|x|]>> and
    <math|f<rsub|i><around*|\||f<rsub|i+1>|\<nobracket\>>> this is called
    Smith Canonical Form of the matrix.
  </theorem>

  <\theorem>
    Let <math|A\<in\>M<rsub|n\<times\>n><around*|(|F<around*|[|x|]>|)>> and
    <math|r=\<rho\><around*|(|A|)>> then the polynomials
    <math|f<rsub|1>,f<rsub|2>,\<ldots\>f<rsub|r>> in the smith canonical form
    of <math|A> are called the invariant factors of <math|A>.
  </theorem>

  <hrule>

  <\lemma>
    If <math|d\<in\>F<around*|[|x|]>> then the smith canonical form of
    <math|x I-c<around*|(|d|)>> is <math|diag<around*|(|1,1,\<ldots\>1,d|)>>.
  </lemma>

  <\proof>
    \;
  </proof>

  <hrule>

  <\theorem>
    For every matrix <math|A\<in\>M<rsub|n\<times\>n><around*|(|F<around*|[|x|]>|)>>
    smith canonical form is unique.
  </theorem>

  <\proof>
    \;
  </proof>

  <hrule>

  Following theorem gives connection between Rational Canonical Form and
  Smith Canonical Form.

  <\theorem>
    Let <math|B\<in\>M<rsub|n\<times\>n><around*|(|F|)>\<nosymbol\>\<nosymbol\>>.
    If the invariant factors of <math|B> are
    <math|d<rsub|1>,\<ldots\>d<rsub|s>> then smith canonical form of <math|x
    I-B> is equal to <math|diag<around*|(|1,1,\<ldots\>,1,d<rsub|1>,\<ldots\>d<rsub|s>|)>>.
  </theorem>

  <\theorem>
    Let <math|A,B\<in\>M<rsub|n\<times\>n><around*|(|F|)>>. Then A is similar
    to <math|B> iff <math|x I-A> is equivalent to <math|x I-B> iff <math|x
    I-A> and <math|x I-B> have the same smith canonical form.
  </theorem>

  <hrule>

  So to test similarity of two matrices <math|A,B\<in\>M<rsub|n*\<times\>n><around*|(|F|)>>
  we resort to following steps:

  <\enumerate-numeric>
    <item>Obtain <math|U,V> such that <math|U <around*|(|x
    I-A|)>V=diag<around*|(|p<rsub|1><around*|(|x|)>,\<ldots\>,p<rsub|n><around*|(|x|)>|)>>

    <item>Obtain <math|R,Q> such that <math|R<around*|(|x
    I-B|)>W=diag<around*|(|q<rsub|1><around*|(|x|)>,\<ldots\>,q<rsub|n><around*|(|x|)>|)>>

    <item>If <math|p<rsub|i>=q<rsub|i>> for
    <math|1\<leqslant\>i\<leqslant\>n> then <math|A\<sim\>B>.

    <item>Suppose similarity holds. Then <math|P<around*|(|x I-A|)>Q=x I -B>
    where <math|P=R<rsup|-1>U> and <math|Q=V W<rsup|-1>> then <math|T>
    \ computed as right value of <math|Q<around*|(|x|)>> at <math|B> and then
    <math|T<rsup|-1>> is left value of <math|P<around*|(|x|)>> at <math|B> is
    such that <math|T A T<rsup|-1>=B>.
  </enumerate-numeric>

  <hrule>

  <section|Fast Fourier Transform>\ 

  This part is mostly covered from ``The Design and Analysis of Computer
  Algorithms'' by Aho, Hopcroft and Ullman.

  <subsection|Bit-Complexity of Fast Fourier Transform>

  <subsection|Schonhage-Strassen algorithm >

  <section|Computational complexity of Fundamental Integer operations.>

  This part is mostly covered from ``The Design and Analysis of Computer
  Algorithms'' by Aho, Hopcroft and Ullman.

  <section|Greatest Common Divisor>

  <\definition>
    <dueto|GCD>If <math|R> is a euclidean ring and <math|a,b\<in\>R> then
    <math|g> is called the <math|GCD<around*|(|a,b|)>> if
    <math|g<around*|\||a|\<nobracket\>>,g<around*|\||b|\<nobracket\>>> and if
    for any <math|h\<in\>R\<nocomma\>,h<around*|\||a|\<nobracket\>>,h<around*|\||b|\<nobracket\>>>
    then <math|h<around*|\||g|\<nobracket\>>>.
  </definition>

  <subsection|Euclidean GCD Algorithm>

  <subsection|Half-GCD Algorithm>

  <section|Polynomial Factoring>

  <subsection|Berlekamp's Method>

  Fix a prime finite field <math|\<bbb-F\><rsub|p>>. Let
  <math|f<around*|(|x|)>\<in\>\<bbb-F\><rsub|p><around*|[|x|]>> and
  <math|deg<around*|(|f|)>=n>. Without loss of generality we shall consider
  <math|f> is a square-free polynomial, for otherwise we can make it square
  free using the following lemma:

  <\definition>
    <dueto|Derivative>If <math|f<around*|(|x|)>\<in\>R<around*|[|x|]>> where
    <math|R> is a ring, and <math|f<around*|(|x|)>=<big|sum>a<rsub|i>x<rsup|i>>
    then we shall define derivative of <math|f> as
    <math|f<rprime|'><around*|(|x|)>=<big|sum>i a<rsub|i>x<rsup|i-1>>.
  </definition>

  <\notation>
    Going further we assume <math|p\<in\>\<bbb-N\>> is a prime number and
    <math|\<bbb-F\><rsub|p>> is the finite field of order <math|p>.
  </notation>

  <\lemma>
    \ <math|f\<in\>\<bbb-F\><rsub|p><around*|[|x|]>> is square-free iff
    <math|gcd<around*|(|f,f<rprime|'>|)>=1>.
  </lemma>

  <\lemma>
    If <math|f\<in\>\<bbb-F\><rsub|p><around*|[|x|]>> is not square-free then
    <math|<frac|f<around*|(|x|)>|g<around*|(|x|)>>> is square-free, where
    <math|g<around*|(|x|)>=gcd<around*|(|f,f<rprime|'>|)>>.
  </lemma>

  <\note>
    There is a procedure to check if given polynomial is irreducible, Ref.
    Mc.William-sloane Ch.4.
  </note>

  To factor the polynomial <math|f<around*|(|x|)>>, the basic intuition is
  that we take the gcd of <math|f<around*|(|x|)>> with ``some'' polynomial,
  such that gcd turns out to be non-trivial.

  Over <math|\<bbb-F\><rsub|p>> we know that <math|x<rsup|p>\<equiv\>x
  <around*|(|mod p|)>,\<forall\>x\<in\>\<bbb-F\><rsub|p>>. Also let
  <math|g<around*|(|x|)>=<around*|(|x<rsup|p>-x|)><rsup|<rprime|'>>=p
  x<rsup|p-1>-1=-1> in <math|\<bbb-F\><rsub|p><around*|[|x|]>>. So
  <math|f<around*|(|x|)>=x<rsup|p>-x> is square-free. Hence
  <math|f<around*|(|x|)>=<around*|(|x<rsup|p>-x|)>=<big|prod><rsub|i\<in\>\<bbb-F\><rsub|p>><around*|(|x-i|)>>.
  So for any <math|v<around*|(|x|)>\<in\>\<bbb-F\><rsub|p><around*|[|x|]>> we
  have <math|<around*|(|v<around*|(|x|)>|)><rsup|p>-v<around*|(|x|)>=<big|prod><rsub|i\<in\>\<bbb-F\><rsub|p>><around*|(|v<around*|(|x|)>-i|)>>.
  And this is a square free splitting as <math|gcd<around*|(|<around*|(|v<around*|(|x|)>-i|)>,<around*|(|v<around*|(|x|)>-j|)>|)>=1>
  for <math|i\<neq\>j>. So for a given square-free <math|f<around*|(|x|)>>,
  if we can find <math|v<around*|(|x|)>> such that
  <math|<around*|(|v<around*|(|x|)>|)><rsup|p>\<equiv\><around*|(|v<around*|(|x|)>|)>
  mod f<around*|(|x|)>> then any irreducible factor of
  <math|f<around*|(|x|)>> will divide exactly one factor
  \ <math|v<around*|(|x|)>-k>. So we shall try to find such
  <math|v<around*|(|x|)>>. We shall start by assuming <math|v<around*|(|x|)>>
  with required property and derive the necessary condition.

  Let <math|f<around*|(|x|)>> be a square-free polynomial in
  <math|\<bbb-F\><rsub|p><around*|[|x|]>> and let <math|v<around*|(|x|)>> be
  a polynomial such that <math|<around*|(|v<around*|(|x|)>|)><rsup|p>-v<around*|(|x|)>\<equiv\>0
  <around*|(|mod f<around*|(|x|)>|)>>. Let
  <math|v<around*|(|x|)>=<big|sum><rsub|0\<leqslant\>i\<leqslant\>t><around*|(|a<rsub|i>x<rsup|i>|)>>
  then in <math|\<bbb-F\><rsub|p><around*|[|x|]>> we have
  <math|<around*|(|v<around*|(|x|)>|)><rsup|p>=<big|sum><rsub|0\<leqslant\>i\<leqslant\>t><around*|(|a<rsub|i>x<rsup|i
  p>|)>>. Then <math|<around*|(|v<around*|(|x|)>|)><rsup|p> <around*|(|mod
  f<around*|(|x|)>|)>=<big|sum><rsub|0\<leqslant\>i\<leqslant\>t>a<rsub|i><around*|(|x<rsup|p
  i> mod f<around*|(|x|)>|)>>. Each of Let <math|x<rsup|p i > mod
  f<around*|(|x|)>> is of degree less than
  <math|n=deg<around*|(|f<around*|(|x|)>|)>>, so we shall each of
  <math|<around*|(|x<rsup|p i> mod f<around*|(|x|)>|)>> as
  <math|<around*|(|<big|sum><rsub|0\<leqslant\>j\<less\>n>b<rsub|i,j>
  x<rsup|j>|)>>. Then we can easily see following holds:

  <\lemma>
    Choose the degree of <math|v<around*|(|x|)>> to be <math|n-1>. Then
    taking the notations above and defining
    <math|B=<around*|(|b<rsub|i,j>|)><rsub|n\<times\>n>>.
    <math|<around*|(|v<around*|(|x|)>|)><rsup|p>-v<around*|(|x|)>\<equiv\>0
    <around*|(|mod f<around*|(|x|)>|)>> iff <math|<wide|v|~> B=<wide|v|~>>,
    where <math|<wide|v|~>=<around*|(|a<rsub|i>|)><rsub|0\<leqslant\>i\<less\>n>>
    is an <math|n> vector of coefficients of <math|v<around*|(|x|)>>.\ 
  </lemma>

  So, <math|<wide|v|~>> is in the null space of <math|B-I>. Since <math|B-I>
  is an <math|n\<times\>n> matrix we can compute the basis of null space
  using sweep-out method in Sec.1 in <math|O<around*|(|n<rsup|3>|)>> steps.
  Let the basis of <math|B-I> be <math|<big|cup><rsub|i\<less\>r><around*|{|v<rsup|<around*|[|i|]>><around*|(|x|)>|}>>.
  Where <math|r=>#of irreducible factors of <math|f<around*|(|x|)>>.\ 

  <subsection|Cantor-Zassenhaus randomized algorithm>

  Let <math|v> be a random linear combination of the basis vectors of the
  null space of <math|B-I>. Compute <math|gcd<around*|(|<around*|(|v<around*|(|x|)>|)><rsup|<frac|p-1|2>>-1,f<around*|(|x|)>|)>=gcd<around*|(|<around*|(|v<around*|(|x|)>|)><rsup|<frac|p-1|2>>-1<around*|(|mod
  f<around*|(|x|)>|)>,f<around*|(|x|)>|)>> (here exponentiation can be done
  in <math|O<around*|(|log p|)>> steps using square-multiply algorithm). We
  can argue that with probability atleast <math|<frac|4|9>> this gives a
  factor of <math|f<around*|(|x|)>>.\ 

  We can analyze the performance by seeing in what all ways can gcd
  computation above can turn out to be trivial?\ 

  <\enumerate-roman>
    <item>If <math|p<rsub|i><around*|(|x|)><around*|\||<around*|(|v<around*|(|x|)>|)><rsup|<frac|p-1|2>>-1|\<nobracket\>>>
    for all <math|i>. In this case gcd is
    <math|<around*|(|v<around*|(|x|)>|)><rsup|<frac|p-1|2>>-1>

    <item>If <math|p<rsub|i><around*|(|x|)>\<nmid\>
    <around*|(|v<around*|(|x|)>|)><rsup|<frac|p-1|2>>-1> for all <math|i>. In
    this case gcd is 1.
  </enumerate-roman>

  \;

  Consider the case i. Given a <math|p<rsub|i><around*|(|x|)>> and
  <math|v<around*|(|x|)>> there is a unique <math|s<rsub|i>> such that
  <math|p<rsub|i><around*|(|x|)><around*|\||v<around*|(|x|)>-s<rsub|i>|\<nobracket\>>>.
  Then <math|<around*|(|v<around*|(|x|)>|)><rsup|<frac|p-1|2>>\<equiv\>1<around*|(|mod
  p<around*|(|x|)>|)>> and <math|<around*|(|v<around*|(|x|)>|)>\<equiv\>s<rsub|i><around*|(|mod
  p<rsub|i><around*|(|x|)>|)>>. Both these conditions imply
  <math|s<rsub|i><rsup|<frac|p-1|2>>\<equiv\>1<around*|(|mod p|)>> which
  happens iff <math|s<rsub|i>> is a Quadratic residue in
  <math|\<bbb-F\><rsub|p>>.\ 

  Assumption: If <math|v<around*|(|x|)>> is chosen randomly from the null
  space of <math|B-I> and <math|s<rsub|i>> is unifomly chosen from
  <math|\<bbb-F\><rsub|p>> Since there are <math|<frac|p-1|2>> quadratic
  residues in <math|\<bbb-F\><rsub|p>>, the probability that <math|s<rsub|i>>
  is a Quadratic residue is <math|<frac|p-1|2 p>>. So probability for trivial
  case i. is <math|<around*|(|<frac|p-1|2 p>|)><rsup|r>>.\ 

  Similarly, <math|gcd<around*|(|<around*|(|v<around*|(|x|)>|)><rsup|<frac|p-1|2>>-1,f<around*|(|x|)>|)>=1>
  iff <math|s<rsub|i>> are all Quadratic Non Residues and this happens with
  probabilty <math|<around*|(|<frac|p+1|2 p>|)><rsup|r>>. So, combining above
  cases probability that <math|gcd<around*|(|<around*|(|v<around*|(|x|)>|)><rsup|<frac|p-1|2>>-1,f<around*|(|x|)>|)>>
  is non-trivial is atlesat <math|1-<around*|(|<frac|p-1|2
  p>|)><rsup|r>-<around*|(|<frac|p+1|2 p>|)><rsup|r>\<gtr\><around*|(|<frac|4|9>|)>>.

  \;

  <subsection|Factorization over <math|\<bbb-Z\><around*|[|x|]>>>

  Let <math|u<around*|(|x|)>\<in\>\<bbb-Z\><around*|[|x|]>> and
  <math|u<around*|(|x|)>=u<rsub|0>+u<rsub|1> x+\<ldots\>+u<rsub|n
  >x<rsup|n>>, without loss of generality assume
  <math|gcd<around*|(|u<rsub|0>,u<rsub|1>,\<ldots\>,u<rsub|n>|)>=1> and
  <math|u<around*|(|x|)>> is square-free.\ 

  <\example>
    <math|f<around*|(|x|)>=x<rsup|8>+x<rsup|6>-3
    x<rsup|4>-3x<rsup|3>+8x<rsup|2>+2x-5> can be factored in
    <math|\<bbb-Z\><rsub|13>> as well as <math|\<bbb-Z\><rsub|2>> but is
    irreducible in <math|\<bbb-Z\>>.
  </example>

  <\note>
    There exist polynomials which have consistent degree factorization in
    <math|\<bbb-Z\><rsub|p>> for every prime <math|p> but not in
    <math|\<bbb-Z\>.>
  </note>

  <\note>
    It is easy to be convinced that almost all polynomials over integers are
    irreducible.
  </note>

  <\lemma>
    Suppose <math|p> is a big enough prime, such that coefficient in any true
    factorization of <math|u<around*|(|x|)>=v<around*|(|x|)>w<around*|(|x|)>>
    be in the range <math|<around*|(|<frac|-p|2>,<frac|p|2>|)>> then
    factoring in <math|\<bbb-Z\><rsub|p>> we obtain true factorization over
    <math|\<bbb-Z\>>.
  </lemma>

  However there are two problems: In general it is difficult to get a good
  bound on <math|p>, <math|p> may be too large. So, solution is to use a
  method called <with|font-series|bold|``Hensel Lifting''>

  <subsubsection|Hensel Lifting>

  <\lemma>
    Let <math|u<around*|(|x|)>,v<around*|(|x|)>,a<around*|(|x|)>> and
    <math|b<around*|(|x|)>> be such that:

    <\enumerate-roman>
      <item> <math|u<around*|(|x|)>=v<around*|(|x|)>w<around*|(|x|)>> in
      <math|\<bbb-Z\><rsub|q>>.\ 

      <item><math|a<around*|(|x|)>v<around*|(|x|)>+b*<around*|(|x|)>w<around*|(|x|)>\<equiv\>1>
      in <math|\<bbb-Z\><rsub|p>>.

      <item><math|c. l<around*|(|v|)>\<equiv\>1<around*|(|mod r|)>>
      <math|<around*|(|l<around*|(|v|)> is the leading coefficient of
      v<around*|(|x|)>|)>>

      <item><math|deg<around*|(|u|)>=deg<around*|(|v|)>+deg<around*|(|w|)>>

      <item><math|r=gcd<around*|(|p,q|)>>
    </enumerate-roman>

    then there exist polynomials <math|V<around*|(|x|)>,W<around*|(|x|)>>
    such that <math|>:

    <\enumerate-roman>
      <item><math|u<around*|(|x|)>=V<around*|(|x|)>W<around*|(|x|)>> in
      <math|\<bbb-Z\><rsub|q r>>.

      <item><math|V<around*|(|x|)>=v<around*|(|x|)>> in
      <math|\<bbb-Z\><rsub|q>>, <math|W<around*|(|x|)>=w<around*|(|x|)>> in
      <math|\<bbb-Z\><rsub|q>>

      <item><math|l<around*|(|v|)>=l<around*|(|V|)>>,
      <math|deg<around*|(|v|)>=deg<around*|(|V|)>>,
      <math|deg<around*|(|w|)>=deg<around*|(|W|)>>.
    </enumerate-roman>
  </lemma>

  <\proof>
    \;
  </proof>

  <hrule>

  <\lemma>
    <dueto|Hensel>Let <math|u<around*|(|x|)>,v<rsub|e><around*|(|x|)>,w<rsub|e><around*|(|x|)>,a<around*|(|x|)>,b<around*|(|x|)>>
    be such that <math|u<around*|(|x|)>=v<rsub|e><around*|(|x|)>w<rsub|e><around*|(|x|)>
    mod p<rsup|2>> and <math|a<around*|(|x|)>v<rsub|e><around*|(|x|)>+b<around*|(|x|)>w<rsub|e><around*|(|x|)>\<equiv\>1<around*|(|mod
    p|)>> where <math|p> is a prime and <math|v<rsub|e><around*|(|x|)>> is
    monic <math|deg<around*|(|a|)>\<leqslant\>deg<around*|(|w<rsub|e>|)>> and
    <math|deg<around*|(|b|)>\<less\>deg<around*|(|v<rsub|e>|)>> and
    <math|deg<around*|(|u|)>=deg<around*|(|v<rsub|e>|)>+deg<around*|(|w<rsub|e>|)>>.
    Then, there are polynomials <math|v<rsub|e+1><around*|(|x|)>> and
    <math|w<rsub|e+1><around*|(|x|)>> satisfying the same conditions <math|e>
    increased by 1. Further <math|v<rsub|e+1><around*|(|x|)>> and
    <math|w<rsub|e+1><around*|(|x|)>> are unique modulo <math|p<rsup|e+1>.>
  </lemma>

  Using this lemma once we have factorization in <math|\<bbb-Z\><rsub|p>> we
  can lift the factorization to <math|\<bbb-Z\><rsub|p<rsup|2>>,\<bbb-Z\><rsub|p<rsup|3>>,\<ldots\>>
  There is an improvement suggested to this by Zessenhaus using which we can
  lift the factorization much faster.\ 

  <hrule>

  <\lemma>
    <dueto|Zessenhaus>Suppose <math|u<around*|(|x|)>\<equiv\>v<around*|(|x|)>w<around*|(|x|)>
    > in <math|\<bbb-Z\><rsub|q>> and <math|a<around*|(|x|)>v<around*|(|x|)>+b<around*|(|x|)>w<around*|(|x|)>=1>
    in <math|\<bbb-Z\><rsub|p>> where <math|p=gcd<around*|(|p,q|)>=r>. Then
    there are polynomials <math|V<around*|(|x|)>,W<around*|(|x|)>,A<around*|(|x|)>,B*<around*|(|x|)>>
    such that <math|u<around*|(|x|)>=V<around*|(|x|)>W<around*|(|x|)> > in
    <math|\<bbb-Z\><rsub|q r>> and <math|A<around*|(|x|)>V<around*|(|x|)>+B<around*|(|x|)>W<around*|(|x|)>\<equiv\>1
    <around*|(|mod p r|)>>.
  </lemma>

  <\proof>
    \;
  </proof>

  <hrule>

  \;

  <section|Ideals and Varieties>

  In this section essentially we will be studying Hilbert Basis Theorem,
  Grobner Basis and Buchberger's Algorithm for computing Grobner's
  Basis<\footnote>
    Grober is Buchberger's Thesis advisor.
  </footnote>. \ 

  <subsection|Multivariate Polynomials>

  Moving from uni-variate to bi-variate or multi-variate polynomial rings
  requires a change in intuition and in this lecture we shall focus on the
  aspects that differentiate them. For example, we know that a polynomial of
  degree <math|n> can have atmost <math|n> roots in any field, but however
  this need not be the case for multivariate polynomials as the following
  example illustrates.

  <\example>
    Consider <math|f\<in\>\<bbb-C\><around*|[|x,y|]>> and
    <math|f<around*|(|x,y|)>=y-x> then any element of the set
    <math|<around*|{|<around*|(|c,c|)><around*|\||c\<in\>\<bbb-C\>|\<nobracket\>>|}>>
    is a root of <math|f> and the set is infinite. So this is an example of a
    polynomial with finite degree with infinite number roots.
  </example>

  <\definition>
    <dueto|Monomial>Given the inderminates of the polynomial ring as
    <math|x<rsub|i>,1\<leqslant\>i\<leqslant\>n> any formal product of the
    form <math|x<rsub|1><rsup|\<alpha\><rsub|1>>x<rsub|2><rsup|\<alpha\><rsub|2>>\<ldots\>x<rsub|n><rsup|\<alpha\><rsub|n>>>
    for <math|\<alpha\><rsub|i>\<geqslant\>0> is called a Monomial.
  </definition>

  <\definition>
    <dueto|Polynomial>If <math|\<bbb-F\>> is a field an element of the ring
    <math|\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>x<rsub|n>|]>> with
    <math|x<rsub|i>> as indeterminates is a set of finite formal sum of the
    form <math|<big|sum><rsub|\<alpha\>>a<rsub|\<alpha\>>x<rsup|\<alpha\>>>
    where <math|\<alpha\>\<in\>\<bbb-N\><rsup|n>>. An element of the ring is
    called Polynomial.
  </definition>

  <\note>
    If <math|\<alpha\>\<in\>\<bbb-N\><rsup|n>> we shall define
    <math|<around*|\||\<alpha\>|\|>=<big|sum><rsub|1\<leqslant\>i\<leqslant\>n>\<alpha\><rsub|i>>.
  </note>

  <\note>
    If <math|f\<in\>\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>
    then <math|deg<around*|(|f|)>=max<around*|(|<around*|{|<around*|\||\<alpha\>|\|>,a<rsub|\<alpha\>>\<neq\>0|}>|)>>
    </note>

  <\definition>
    <dueto|Monomial Ordering>Given <math|x<rsub|i>,1\<leqslant\>i\<leqslant\>n>
    as inderminates, Monomial ordering is a linear ordering
    <math|<around*|(|\<gtr\>|)>> on the set of monomials formed with those
    inderminates satsisfying certain regularity properties:

    <\enumerate-roman>
      <item>If <math|\<alpha\>,\<beta\>,\<gamma\>> are monomials such that
      <math|\<alpha\>\<gtr\>\<beta\>> then
      <math|\<alpha\>\<gamma\>\<gtr\>\<beta\>\<gamma\>>.

      <item><math|\<gtr\>> is a well-ordering on set of Monomials.
    </enumerate-roman>
  </definition>

  <\note>
    It is obvious to see that ordering of monomials formed with <math|n>
    indeterminates transforms into ordering on <math|\<bbb-N\><rsup|n>>.
    Going forward we shall interchange between these ideas.
  </note>

  <\example>
    <dueto|Lex>Given <math|\<alpha\>,\<beta\>\<in\>\<bbb-N\><rsup| n>> we say
    that <math|\<alpha\>\<gtr\><rsub|Lex>\<beta\>> if the left most non-zero
    entry of <math|\<alpha\>-\<beta\>> is positive.
  </example>

  <\example>
    <dueto|Graded Lex>Given <math|\<alpha\>,\<beta\>\<in\>\<bbb-N\><rsup|n>>
    we say that <math|\<alpha\>\<gtr\><rsub|GrLex>\<beta\>> if
    <math|<around*|\||\<alpha\>|\|>\<gtr\><around*|\||\<beta\>|\|>> or if
    <math|<around*|\||\<alpha\>|\|>=<around*|\||\<beta\>|\|>> then
    <math|\<alpha\>\<gtr\><rsub|Lex>\<beta\>>.
  </example>

  <\exercise>
    Prove that Lex and Graded Lex orderings are Monomial Orderings.
  </exercise>

  <\definition>
    Let <math|f<around*|(|x|)>=<big|sum><rsub|\<alpha\>>a<rsub|\<alpha\>>x<rsup|\<alpha\>>\<in\>\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>
    and <math|\<gtr\>> be a monomial ordering on
    <math|x<rsub|i>,1\<leqslant\>i\<leqslant\>n> and <math|f\<neq\>0>. Then
    we define the following:

    <\enumerate-roman>
      <item><math|multideg<around*|(|f|)>=>max
      <math|<around*|{|\<alpha\>\<in\>\<bbb-N\><rsup|n><around*|\||a<rsub|\<alpha\>>\<neq\>0|\<nobracket\>>|}>>

      <item><math|leadingCoefficient<around*|(|f|)>> =
      <math|a<rsub|multideg<around*|(|f|)>>>

      <item><math|leadingMonomial<around*|(|f|)>> =
      <math|x<rsup|multideg<around*|(|f|)>>>

      <item><math|leadingTerm<around*|(|f|)>>=
      <math|a<rsub|multideg<around*|(|f|)>>x<rsup|multideg<around*|(|f|)>>>
    </enumerate-roman>
  </definition>

  <\proposition>
    Given <math|f,g\<in\>\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>
    then we have the following properties:

    <\enumerate-roman>
      <item><math|multideg<around*|(|f g|)>=><math|multideg<around*|(|f|)>+><math|multideg<around*|(|g|)>>

      <item><math|f+g\<neq\>0 \<Rightarrow\>>
      <math|multideg<around*|(|f+g|)>\<leqslant\>
      max<around*|(|multideg<around*|(|f|)>,multideg<around*|(|g|)>|)>> and
      if <math|multideg<around*|(|f|)>\<neq\>multideg<around*|(|g|)>> then
      equalitiy holds, however this is not a necessary condition.
    </enumerate-roman>
  </proposition>

  <subsection|Division algorithm in <math|\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>>

  In this we primarily aim at investigating membership of
  <math|f\<in\>\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>> in an
  ideal generated by some elements of the ring. More precisely, given
  <math|f<rsub|1>,\<ldots\>f<rsub|s>\<in\>\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>
  we would like to know if there exist <math|a<rsub|i>,1\<leqslant\>i\<leqslant\>s>
  such that <math|f=<big|sum><rsub|1\<leqslant\>i\<leqslant\>s>a<rsub|i>f<rsub|i>+r>
  where <math|r,a<rsub|i>\<in\>\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>.

  <\note>
    In such a decomposition of <math|f> shown above the coefficients of
    <math|f<rsub|i>> generally depend on the chosen Monomial ordering.
  </note>

  <\theorem>
    Let <math|<around*|(|f<rsub|1>,\<ldots\>,f<rsub|s>|)>> be an ordered
    tuple of polynomials in <math|\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>
    then every <math|f\<in\>\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>
    can be written as <math|f=<big|sum><rsub|1\<leqslant\>i\<leqslant\>s>a<rsub|i>f<rsub|i>+r>,
    where <math|a<rsub|i>,r\<in\>\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>
    and either <math|r=0> or <math|r> is such that it is divisible by none of
    <math|leadingTerm<around*|(|f<rsub|i>|)>>.
  </theorem>

  <\note>
    <math|r=0> is sufficient to show that
    <math|f\<in\>\<less\>f<rsub|1>,\<ldots\>,f<rsub|s>\<gtr\>> but not
    necessary. This is evident from the following example.
  </note>

  <\example>
    Let <math|f<around*|(|x,y|)>=x y<rsup|2>-x> and
    <math|f<rsub|1><around*|(|x,y|)>=x y+1> and
    <math|f<rsub|2><around*|(|x,y|)>=y<rsup|2>-1> considering the monomial
    ordering as <math|\<gtr\><rsub|Lex>> we have <math|x
    y<rsup|2>-x=y<around*|(|x y+1|)>+0<around*|(|y<rsup|2>-1|)>+<around*|(|-x-y|)>>
    if we considering ordering on <math|f<rsub|i>> as
    <math|f<rsub|1>\<gtr\>f<rsub|2>>, else we get <math|x
    y<rsup|2>-x=x<around*|(|y<rsup|2>-1|)>+0<around*|(|x y+1|)>+0>.
  </example>

  \;

  \;

  \;

  \;

  \;
</body>

<\references>
  <\collection>
    <associate|auto-1|<tuple|1|2>>
    <associate|auto-10|<tuple|3.0.3|7>>
    <associate|auto-11|<tuple|4|9>>
    <associate|auto-12|<tuple|5|10>>
    <associate|auto-13|<tuple|6|13>>
    <associate|auto-14|<tuple|6.1|13>>
    <associate|auto-15|<tuple|6.2|13>>
    <associate|auto-16|<tuple|7|13>>
    <associate|auto-17|<tuple|8|13>>
    <associate|auto-18|<tuple|8.1|13>>
    <associate|auto-19|<tuple|8.2|13>>
    <associate|auto-2|<tuple|1.1|2>>
    <associate|auto-20|<tuple|9|13>>
    <associate|auto-21|<tuple|9.1|13>>
    <associate|auto-22|<tuple|9.2|14>>
    <associate|auto-23|<tuple|9.3|15>>
    <associate|auto-24|<tuple|9.3.1|15>>
    <associate|auto-25|<tuple|10|16>>
    <associate|auto-26|<tuple|10.1|16>>
    <associate|auto-27|<tuple|10.2|17>>
    <associate|auto-3|<tuple|1.2|2>>
    <associate|auto-4|<tuple|1.3|2>>
    <associate|auto-5|<tuple|2|3>>
    <associate|auto-6|<tuple|2.1|3>>
    <associate|auto-7|<tuple|3|6>>
    <associate|auto-8|<tuple|3.0.1|6>>
    <associate|auto-9|<tuple|3.0.2|7>>
    <associate|footnote-1|<tuple|1|16>>
    <associate|footnr-1|<tuple|1|16>>
  </collection>
</references>

<\auxiliary>
  <\collection>
    <\associate|toc>
      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|1<space|2spc>Introduction>
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-1><vspace|0.5fn>

      <with|par-left|<quote|1tab>|1.1<space|2spc>Overview
      \ <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-2>>

      <with|par-left|<quote|1tab>|1.2<space|2spc>References
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-3>>

      <with|par-left|<quote|1tab>|1.3<space|2spc>Evaluation
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-4>>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|2<space|2spc>Hermite
      Canonical Form> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-5><vspace|0.5fn>

      <with|par-left|<quote|1tab>|2.1<space|2spc>Sweep-out Method
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-6>>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|3<space|2spc>LUP
      decomposition of Matrix and Applications>
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-7><vspace|0.5fn>

      <with|par-left|<quote|2tab>|3.0.1<space|2spc>Efficient Methods for
      Multiplying Matrices and Polynomials
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-8>>

      <with|par-left|<quote|2tab>|3.0.2<space|2spc>Matrix Multiplication
      <with|mode|<quote|math>|\<Leftrightarrow\>> Matrix Inversion
      \ <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-9>>

      <with|par-left|<quote|2tab>|3.0.3<space|2spc>Computing matrix
      determinant. <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-10>>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|4<space|2spc>Upper
      Hessenberg Form> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-11><vspace|0.5fn>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|5<space|2spc>Smith
      Canonical Form> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-12><vspace|0.5fn>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|6<space|2spc>Fast
      Fourier Transform> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-13><vspace|0.5fn>

      <with|par-left|<quote|1tab>|6.1<space|2spc>Bit-Complexity of Fast
      Fourier Transform <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-14>>

      <with|par-left|<quote|1tab>|6.2<space|2spc>Schonhage-Strassen algorithm
      \ <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-15>>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|7<space|2spc>Computational
      complexity of Fundamental Integer operations.>
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-16><vspace|0.5fn>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|8<space|2spc>Greatest
      Common Divisor> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-17><vspace|0.5fn>

      <with|par-left|<quote|1tab>|8.1<space|2spc>Euclidean GCD Algorithm
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-18>>

      <with|par-left|<quote|1tab>|8.2<space|2spc>Half-GCD Algorithm
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-19>>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|9<space|2spc>Polynomial
      Factoring> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-20><vspace|0.5fn>

      <with|par-left|<quote|1tab>|9.1<space|2spc>Berlekamp's Method
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-21>>

      <with|par-left|<quote|1tab>|9.2<space|2spc>Cantor-Zassenhaus randomized
      algorithm <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-22>>

      <with|par-left|<quote|1tab>|9.3<space|2spc>Factorization over
      <with|mode|<quote|math>|\<bbb-Z\><around*|[|x|]>>
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-23>>

      <with|par-left|<quote|2tab>|9.3.1<space|2spc>Hensel Lifting
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-24>>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|10<space|2spc>Ideals
      and Varieties> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-25><vspace|0.5fn>

      <with|par-left|<quote|1tab>|10.1<space|2spc>Multivariate Polynomials
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-26>>

      <with|par-left|<quote|1tab>|10.2<space|2spc>Division algorithm in
      <with|mode|<quote|math>|\<bbb-F\><around*|[|x<rsub|1>,\<ldots\>,x<rsub|n>|]>>
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-27>>
    </associate>
  </collection>
</auxiliary>